{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import mneflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. from MNE epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you use MNE-python, all you need is to provide your epochs file (or list of epoch files) to mneflow.produce_tfrecords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mne\n",
    "#from mne.datasets import multimodal\n",
    "# mne.set_log_level(verbose='CRITICAL')\n",
    "# #print(__doc__)\n",
    "\n",
    "# fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')\n",
    "# raw = mne.io.read_raw_fif(fname_raw)\n",
    "\n",
    "# #event_id = {}\n",
    "# cond = raw.acqparser.get_condition(raw, None)\n",
    "# epochs_list = [mne.Epochs(raw, **c) for c in cond]\n",
    "# #here we concatenate epochs because each input file contains just one condition\n",
    "# #otherwise mneflow.produce_tfrecords can handle a list of epochs objects\n",
    "# epochs = mne.concatenate_epochs(epochs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify import options\n",
    "import_opt = dict(savepath='../my_TFRs/', #path to where the TFR files will be saved\n",
    "           out_name='mne_sample_epochs', #name of TFRecords files\n",
    "           input_type='epochs', #can also be \"epochs\"\n",
    "           picks={'meg':'grad'}, #used only if input_type is mne.epochs.Epochs or path to saved '*-epo.fif'\n",
    "           scale=True, #apply baseline_scaling?\n",
    "           crop_baseline=True,\n",
    "           bp_filter = (1.,45.),\n",
    "           decimate = 2,\n",
    "           scale_interval=78, #baseline, TODO: define automatically for epochs objects\n",
    "           savebatch=8, # number of input files per TFRecord file           \n",
    "           save_orig=False, # whether to produce separate TFR-file for inputs in original order\n",
    "           val_size=0.1)\n",
    "\n",
    "#whenever you import a dataset a copy of meta is also saved to savepath/meta.pkl so it can be restored at any time\n",
    "if os.path.exists(import_opt['savepath']+'meta.pkl'):\n",
    "    meta = mneflow.load_meta(import_opt['savepath'])\n",
    "else:\n",
    "    meta = mneflow.produce_tfrecords(epochs,**import_opt)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if your epochs are saved to disk provide a str (or list of str) with path(s) to your -epo.fif files\n",
    "\n",
    "e.g. this will work\n",
    "\n",
    "```python\n",
    "epochs.save('test_saved_epochs.fif')\n",
    "meta = mneflow.produce_tfrecords('test_saved_epochs.fif',**opt)\n",
    "```\n",
    "\n",
    "if the first argument is str this function can also accept *.mat or *.npz format\n",
    "\n",
    "e.g.\n",
    "\n",
    "```python\n",
    "data_path = '/m/nbe/scratch/braindata/izbrv/detection_data/'\n",
    "filenames = [data_path +'sub' + str(i) + '-grad.npz' for i in range(1,4)]\n",
    "meta = mneflow.produce_tfrecords(filenames,**opt)\n",
    "```\n",
    "In this case, specify iput_type='array', and also provide array_keys keyword argument\n",
    "\n",
    "e.g. \n",
    "\n",
    "```python\n",
    "array_keys={'X':'my_data_samples','y':'my_labels'}\n",
    "```\n",
    "#note that \"picks\" works only for input_type=\"epochs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose from already implemented models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /u/62/zubarei1/unix/.conda/envs/py3ml/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "lf-conv _init\n",
      "WARNING:tensorflow:From /m/home/home6/62/zubarei1/data/Desktop/projects/papers/DLforMEG/mneflow/mneflow/layers.py:52: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "dense _init\n",
      "Initialization complete!\n"
     ]
    }
   ],
   "source": [
    "#specify model parameters\n",
    "params = dict(l1_lambda=1e-7,\n",
    "              learn_rate=3e-4,\n",
    "              dropout = .5,\n",
    "              patience = 3,# patientce for early stopping\n",
    "              min_delta = 5e-6,\n",
    "              test_upd_batch = 20,#pseudo-real time test batch size\n",
    "              n_epochs = 1000, #total training epochs\n",
    "              eval_step = 50, #evaluate validation loss each 10 epochs\n",
    "              n_batch = 200,\n",
    "              #these are specific to LF-CNN]\n",
    "              n_ls=32, #number of latent factors\n",
    "              nonlin_in = tf.identity, #input layer activation for var-cnn and lf-cnn\n",
    "              nonlin_hid = tf.nn.relu, #convolution layer activation for var-cnn and lf-cnn\n",
    "              nonlin_out = tf.identity, #output layer activation for var-cnn and lf-cnn\n",
    "              filter_length=32, #convolutional filter length for var-cnn and lf-cnn\n",
    "              pooling = 6, #convlayer pooling factor for var-cnn and lf-cnn\n",
    "              stride = 1, #stride parameter for convolution filter\n",
    "              ) #training batch size) \n",
    "\n",
    "#specify the path to store the saved model\n",
    "model_path = '/m/nbe/scratch/braindata/izbrv/detection_data/tfr/'\n",
    "\n",
    "model = mneflow.models.LFCNN(meta,params,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train_loss 2.21819, train acc 0.152174 val loss 2.49855, val acc 0.117021\n",
      "epoch 50, train_loss 0.568426, train acc 0.869565 val loss 1.3934, val acc 0.446809\n",
      "epoch 100, train_loss 0.108891, train acc 1 val loss 0.690103, val acc 0.776596\n",
      "epoch 150, train_loss 0.0415108, train acc 1 val loss 0.600958, val acc 0.797872\n",
      "epoch 200, train_loss 0.0132537, train acc 1 val loss 0.44546, val acc 0.87234\n",
      "* Patience count 1\n",
      "epoch 300, train_loss 0.0137334, train acc 1 val loss 0.381117, val acc 0.93617\n",
      "* Patience count 2\n",
      "* Patience count 3\n",
      "* Patience count 4\n",
      "* Patience count 5\n",
      "early stopping...\n",
      "WARNING:tensorflow:From /u/62/zubarei1/unix/.conda/envs/py3ml/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /m/nbe/scratch/braindata/izbrv/detection_data/tfr/lf-cnn-mne_sample_epochs\n",
      "stopped at: epoch 500, val loss 0.381117, val acc 0.93617\n",
      "Trained in 137.08s\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "start = time()\n",
    "model.train()\n",
    "stop = time() - start\n",
    "print('Trained in {:.2f}s'.format(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate performance\n",
    "#TODO: add across-subject example\n",
    "#test_accs = model.evaluate_performance(meta['orig_paths'], batch_size=120)\n",
    "#prt_test_acc, prt_logits = model.evaluate_realtime(meta['orig_paths'], batch_size=120, step_size=params['test_upd_batch'])\n",
    "#results = {'val_acc':model.v_acc[0], 'test_init':np.mean(test_accs), 'test_upd':np.mean(prt_test_acc), 'sid':meta['architecture']} # 'train_time':stop,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compute_patterns(output='patterns')\n",
    "#explore output layer weights\n",
    "#TODO: Fix bug related to varying sampling rates and pooling factors\n",
    "#f = model.plot_out_weihts()\n",
    "\n",
    "#explore informative spatial patterns(LF-CNN only)\n",
    "#TODO: Fix visualizations\n",
    "f = model.plot_patterns(sensor_layout='Vectorview-grad', sorting='best', spectra=True, scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify your own neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete!\n",
      "epoch 0, train_loss 1.81289, train acc 0.630435 val loss 1.73704, val acc 0.691489\n",
      "epoch 50, train_loss 1.27426, train acc 1 val loss 1.39943, val acc 0.93617\n",
      "epoch 100, train_loss 1.27419, train acc 1 val loss 1.39228, val acc 0.93617\n",
      "* Patience count 1\n",
      "* Patience count 2\n",
      "epoch 250, train_loss 1.27413, train acc 1 val loss 1.38655, val acc 0.93617\n",
      "* Patience count 3\n",
      "early stopping...\n",
      "INFO:tensorflow:Restoring parameters from /m/nbe/scratch/braindata/izbrv/detection_data/tfr/my_own-mne_sample_epochs\n",
      "stopped at: epoch 300, val loss 1.38655, val acc 0.93617\n",
      "Trained in 113.67s\n"
     ]
    }
   ],
   "source": [
    "#let's make a simple linear classifier using all channels*timepoints as features with keras\n",
    "params = dict(l1_lambda=0,\n",
    "              learn_rate=3e-4,\n",
    "              dropout = .5,\n",
    "              patience = 3,# patientce for early stopping\n",
    "              min_delta = 5e-3, #note the increased convergence threshold1\n",
    "              test_upd_batch = 20,#pseudo-real time test batch size\n",
    "              n_epochs = 1000, #total training epochs\n",
    "              #nonlin_out=tf.identity,\n",
    "              eval_step = 50, #evaluate validation loss each 10 epochs\n",
    "              n_batch = 200) #training batch size) \n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "\n",
    "\n",
    "class MyNetwork(mneflow.models.Model):\n",
    "    #all you need to do is to override the computational graph with your own\n",
    "    def _build_graph(self):\n",
    "        self.h_params['architecture'] = 'my_own'\n",
    "        input_main   = self.X\n",
    "        flatten      = Flatten()(input_main)\n",
    "        dense        = Dense(self.h_params['n_classes'], kernel_constraint = max_norm(0.5))(flatten)\n",
    "        y_pred      = Activation('softmax')(dense)\n",
    "        return y_pred\n",
    "    \n",
    "m2 = MyNetwork(meta,params,model_path)\n",
    "\n",
    "start = time()\n",
    "m2.train()\n",
    "stop = time() - start\n",
    "print('Trained in {:.2f}s'.format(stop))\n",
    "\n",
    "\n",
    "# #evaluate performance\n",
    "# test_accs = m2.evaluate_performance(meta['orig_paths'], batch_size=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that our \"custom\" model performed equally well as LF-CNN in terms of accuracy on the validation set. Yet, the loss function estimate on the validation set is much lower for LF-CNN. This result is not very surprising, since LF-CNN has much more constrained solution space optimized for across-subjects decoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: across-subject/leave-one-subject-out example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
